{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7376252d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ [æå–éŸ³é¢‘] audio_recording.webm -> output_audio.wav\n",
      "ğŸ“Œ [è®°å½•é¼ æ ‡ç‚¹å‡»] ç›‘å¬ä¸­... (æŒ‰ 'q' é€€å‡º)\n",
      "ğŸ“Œ [åˆ†æéŸ³é¢‘] è®¡ç®—éŸ³é¢‘å³°å€¼: output_audio.wav\n",
      "ğŸ“Œ [å›¾åƒå˜åŒ–æ£€æµ‹] åˆ†æä¸­: screen_recording.webm\n",
      "âœ… [å›¾åƒå˜åŒ–æ£€æµ‹] å…±æ£€æµ‹åˆ° 4 ä¸ªé«˜å˜åŒ–å¸§ï¼Œå·²ä¿å­˜è‡³ high_diff_frames\n",
      "ğŸ“Œ [é€‰æ‹©å…³é”®å¸§] è®¡ç®—ä¸­...\n",
      "âœ… [é€‰æ‹©å…³é”®å¸§] é€‰å–çš„æ—¶é—´æˆ³: [np.float64(0.5340589569160997), np.float64(20.54965986394558), np.float64(49.0637641723356), np.float64(72.14439909297052)]\n",
      "ğŸ“Œ [æå–è§†é¢‘ç‰‡æ®µ] å¤„ç†ä¸­: screen_recording.webm\n",
      "ğŸ¬ [æå–è§†é¢‘ç‰‡æ®µ] ç‰‡æ®µ 1 å®Œæˆ: key_frames\\clip_1.webm\n",
      "ğŸ¬ [æå–è§†é¢‘ç‰‡æ®µ] ç‰‡æ®µ 2 å®Œæˆ: key_frames\\clip_2.webm\n",
      "ğŸ¬ [æå–è§†é¢‘ç‰‡æ®µ] ç‰‡æ®µ 3 å®Œæˆ: key_frames\\clip_3.webm\n",
      "ğŸ¬ [æå–è§†é¢‘ç‰‡æ®µ] ç‰‡æ®µ 4 å®Œæˆ: key_frames\\clip_4.webm\n",
      "ğŸ“Œ [ç”Ÿæˆå…³é”®å¸§æˆªå›¾] å¼€å§‹: screen_recording.webm\n",
      "ğŸ–¼ï¸ [ç”Ÿæˆå…³é”®å¸§æˆªå›¾] æˆªå›¾ 1 æˆåŠŸ: key_frames\\frame_1.jpg\n",
      "ğŸ–¼ï¸ [ç”Ÿæˆå…³é”®å¸§æˆªå›¾] æˆªå›¾ 2 æˆåŠŸ: key_frames\\frame_2.jpg\n",
      "ğŸ–¼ï¸ [ç”Ÿæˆå…³é”®å¸§æˆªå›¾] æˆªå›¾ 3 æˆåŠŸ: key_frames\\frame_3.jpg\n",
      "ğŸ–¼ï¸ [ç”Ÿæˆå…³é”®å¸§æˆªå›¾] æˆªå›¾ 4 æˆåŠŸ: key_frames\\frame_4.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import librosa\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "\n",
    "video_screen = \"screen_recording.webm\"\n",
    "audio_file = \"audio_recording.webm\"\n",
    "\n",
    "# 1. Extract audio for analysis\n",
    "def extract_audio(video_path, audio_path):\n",
    "    print(f\"ğŸ“Œ [æå–éŸ³é¢‘] {video_path} -> {audio_path}\")\n",
    "    command = [\"ffmpeg\", \"-i\", video_path, \"-q:a\", \"0\", \"-map\", \"a\", audio_path, \"-y\"]\n",
    "    subprocess.run(command)\n",
    "\n",
    "# 2. Calculate audio peak timestamps\n",
    "def get_audio_peaks(audio_path, sr=22050):\n",
    "    print(f\"ğŸ“Œ [åˆ†æéŸ³é¢‘] è®¡ç®—éŸ³é¢‘å³°å€¼: {audio_path}\")\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    rms = librosa.feature.rms(y=y)[0]\n",
    "    peaks = np.where(rms > np.percentile(rms, 90))[0]\n",
    "    return librosa.frames_to_time(peaks, sr=sr)\n",
    "\n",
    "# 3. Simulate recording of mouse clicksï¼ˆç©ºå®ç°ä¿ç•™ç»“æ„ï¼‰\n",
    "def record_mouse_clicks(video_path, csv_path):\n",
    "    print(f\"ğŸ“Œ [è®°å½•é¼ æ ‡ç‚¹å‡»] ç›‘å¬ä¸­... (æŒ‰ 'q' é€€å‡º)\")\n",
    "    video_start_time = time.time()\n",
    "    with open(csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['relative_timestamp'])\n",
    "        # å¯é€‰æ‰‹åŠ¨æ·»åŠ æ¨¡æ‹Ÿç‚¹å‡»ï¼š writer.writerow([12.5])\n",
    "\n",
    "# 4. Get mouse click times (CSV)\n",
    "def get_mouse_click_times(csv_path):\n",
    "    if not os.path.exists(csv_path):\n",
    "        return np.array([])\n",
    "    with open(csv_path, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        return np.array([float(row[0]) for row in reader if row])\n",
    "\n",
    "# 5. Get timestamps of frames with drastic visual changes\n",
    "def get_visual_change_times(video_path, threshold=0.5, frame_rate=1, save_folder=\"visual_changes\"):\n",
    "    print(f\"ğŸ“Œ [å›¾åƒå˜åŒ–æ£€æµ‹] åˆ†æä¸­: {video_path}\")\n",
    "    temp_folder = \"temp_frames\"\n",
    "    os.makedirs(temp_folder, exist_ok=True)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    # Extract frames\n",
    "    command = [\n",
    "        \"ffmpeg\", \"-i\", video_path, \"-vf\", f\"fps={frame_rate}\",\n",
    "        os.path.join(temp_folder, \"frame_%04d.jpg\"), \"-hide_banner\", \"-loglevel\", \"error\", \"-y\"\n",
    "    ]\n",
    "    subprocess.run(command)\n",
    "\n",
    "    # Analyse frame hash differences\n",
    "    timestamps = []\n",
    "    prev_hash = None\n",
    "    for i, fname in enumerate(sorted(os.listdir(temp_folder))):\n",
    "        img_path = os.path.join(temp_folder, fname)\n",
    "        with Image.open(img_path) as img:\n",
    "            img_hash = imagehash.phash(img)\n",
    "\n",
    "        if prev_hash is not None:\n",
    "            diff = (prev_hash - img_hash) / len(img_hash.hash) ** 2\n",
    "            if diff >= threshold:\n",
    "                save_path = os.path.join(save_folder, fname)\n",
    "                img.save(save_path)\n",
    "                timestamps.append(i / frame_rate)\n",
    "\n",
    "        prev_hash = img_hash\n",
    "\n",
    "    print(f\"âœ… [å›¾åƒå˜åŒ–æ£€æµ‹] å…±æ£€æµ‹åˆ° {len(timestamps)} ä¸ªé«˜å˜åŒ–å¸§ï¼Œå·²ä¿å­˜è‡³ {save_folder}\")\n",
    "    return np.array(timestamps)\n",
    "\n",
    "# 6. Merge timestamps and select keyframes (deinterlacing)\n",
    "def get_final_key_frames(audio_peaks, mouse_clicks, visual_changes, min_gap=20, max_clips=10):\n",
    "    print(f\"ğŸ“Œ [é€‰æ‹©å…³é”®å¸§] è®¡ç®—ä¸­...\")\n",
    "    combined_times = np.concatenate((audio_peaks, mouse_clicks, visual_changes))\n",
    "    combined_times.sort()\n",
    "\n",
    "    final_times = []\n",
    "    for time in combined_times:\n",
    "        if all(abs(time - t) >= min_gap for t in final_times):\n",
    "            final_times.append(time)\n",
    "        if len(final_times) >= max_clips:\n",
    "            break\n",
    "\n",
    "    print(f\"âœ… [é€‰æ‹©å…³é”®å¸§] é€‰å–çš„æ—¶é—´æˆ³: {final_times}\")\n",
    "    return final_times\n",
    "\n",
    "# 7. Extract Video Clip\n",
    "def extract_video_clips(video_path, timestamps, output_folder, clip_duration=10):\n",
    "    print(f\"ğŸ“Œ [æå–è§†é¢‘ç‰‡æ®µ] å¤„ç†ä¸­: {video_path}\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for i, timestamp in enumerate(timestamps):\n",
    "        start_time = max(timestamp - 5, 0)\n",
    "        output_clip = os.path.join(output_folder, f\"clip_{i+1}.webm\")\n",
    "        command = [\n",
    "            \"ffmpeg\", \"-ss\", str(start_time), \"-i\", video_path, \"-t\", str(clip_duration),\n",
    "            \"-an\",  # no voice\n",
    "            \"-c:v\", \"libvpx-vp9\", \"-crf\", \"30\", \"-b:v\", \"0\",\n",
    "            \"-y\", output_clip\n",
    "        ]\n",
    "        subprocess.run(command)\n",
    "        print(f\"ğŸ¬ [æå–è§†é¢‘ç‰‡æ®µ] ç‰‡æ®µ {i+1} å®Œæˆ: {output_clip}\")\n",
    "\n",
    "# 8. Extract Keyframe Screenshot\n",
    "def extract_screenshots(video_path, timestamps, output_folder):\n",
    "    print(f\"ğŸ“Œ [ç”Ÿæˆå…³é”®å¸§æˆªå›¾] å¼€å§‹: {video_path}\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for i, timestamp in enumerate(timestamps):\n",
    "        output_image = os.path.join(output_folder, f\"frame_{i+1}.jpg\")\n",
    "        command = [\n",
    "            \"ffmpeg\", \"-ss\", str(timestamp), \"-i\", video_path,\n",
    "            \"-vframes\", \"1\", \"-q:v\", \"2\", \"-y\", output_image\n",
    "        ]\n",
    "        result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"ğŸ–¼ï¸ [ç”Ÿæˆå…³é”®å¸§æˆªå›¾] æˆªå›¾ {i+1} æˆåŠŸ: {output_image}\")\n",
    "        else:\n",
    "            print(f\"âŒ [ç”Ÿæˆå…³é”®å¸§æˆªå›¾] å¤±è´¥: {result.stderr}\")\n",
    "\n",
    "\n",
    "# main program\n",
    "\n",
    "# Extract audio\n",
    "audio_path = \"output_audio.wav\"\n",
    "extract_audio(audio_file, audio_path)\n",
    "\n",
    "# Record mouse clicks\n",
    "mouse_click_log = \"mouse_clicks.csv\"\n",
    "record_mouse_clicks(video_screen, mouse_click_log)\n",
    "\n",
    "# Extract event time points\n",
    "audio_peaks = get_audio_peaks(audio_path)\n",
    "mouse_clicks = get_mouse_click_times(mouse_click_log)\n",
    "visual_changes = get_visual_change_times(video_screen, save_folder=\"high_diff_frames\")\n",
    "\n",
    "# Filter keyframe time points\n",
    "final_key_frames = get_final_key_frames(audio_peaks, mouse_clicks, visual_changes)\n",
    "\n",
    "# Export Video Clip + Screenshot\n",
    "if final_key_frames:\n",
    "    extract_video_clips(video_screen, final_key_frames, \"key_frames\")\n",
    "    extract_screenshots(video_screen, final_key_frames, \"key_frames\")\n",
    "else:\n",
    "    print(\"No valid keyframes, skip video clip and screenshot extraction!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
